"""
ë¦¬ë·° ìë™í™” SaaS ì„œë¹„ìŠ¤ - FastAPI ë°±ì—”ë“œ - 24ì‹œê°„ ìë™í™” êµ¬í˜„
"""
import os
import sys
import asyncio
import time
from pathlib import Path
from datetime import datetime, timedelta
from fastapi import FastAPI, Request, Depends
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from api.routes import reply_posting
from contextlib import asynccontextmanager
import logging
import nest_asyncio
import traceback

# 24ì‹œê°„ ìë™í™”ë¥¼ ìœ„í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# ì„œë¹„ìŠ¤ ì„í¬íŠ¸
from api.services.review_collector_service import ReviewCollectorService
from api.services.reply_posting_service import ReplyPostingService
from api.services.ai_service import AIService
from api.services.supabase_service import SupabaseService, get_supabase_service
from api.services.encryption import decrypt_password
from config.openai_client import get_openai_client

# Windowsì—ì„œ Playwright í˜¸í™˜ì„±ì„ ìœ„í•´ SelectorEventLoopPolicy ì‚¬ìš©
# nest_asyncio ì ìš© ì „ì— ì„¤ì •í•´ì•¼ í•¨
if sys.platform == 'win32':
    # Playwright async APIë¥¼ ìœ„í•œ í•„ìˆ˜ ì„¤ì •
    from asyncio import WindowsSelectorEventLoopPolicy
    asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())

# nest_asyncioëŠ” ì´ë²¤íŠ¸ë£¨í”„ ì •ì±… ì„¤ì • í›„ì— ì ìš©
nest_asyncio.apply()

BASE_DIR = Path(__file__).resolve().parent.parent

# ë¡œê·¸ ì„¤ì •
log_dir = os.path.join(BASE_DIR, 'logs')
os.makedirs(log_dir, exist_ok=True)

log_file = os.path.join(log_dir, f'app_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±
scheduler = AsyncIOScheduler()

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ë¦¬ë·° ìë™í™” ì„œë¹„ìŠ¤ ì‹œì‘...")
    
    # â­ ì¡°ê±´ë¶€ ì‹¤í–‰ ë¡œì§ ì¶”ê°€
    enable_auto_start = os.getenv("AUTO_START_JOBS", "false").lower() == "true"
    
    if enable_auto_start:
        logger.info("ğŸš€ ìë™í™” ëª¨ë“œ: ì¦‰ì‹œ ì‹¤í–‰ + ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
        # ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ - ì¦‰ì‹œ ì‹¤í–‰ í¬í•¨
        await startup_scheduler()
    else:
        logger.info("ğŸŒ ì›¹ì„œë²„ ëª¨ë“œ: ìŠ¤ì¼€ì¤„ëŸ¬ë§Œ ë“±ë¡ (ì¦‰ì‹œ ì‹¤í–‰ ì—†ìŒ)")
        # ìŠ¤ì¼€ì¤„ëŸ¬ë§Œ ë“±ë¡, ì¦‰ì‹œ ì‹¤í–‰ ì•ˆí•¨
        await setup_scheduler_only()
    
    yield
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ
    if scheduler.running:
        scheduler.shutdown()
    
    logger.info("ë¦¬ë·° ìë™í™” ì„œë¹„ìŠ¤ ì¢…ë£Œ...")

app = FastAPI(
    title="ë¦¬ë·° ìë™í™” API",
    description="ë°°ë¯¼, ìš”ê¸°ìš”, ì¿ íŒ¡ì´ì¸  ë¦¬ë·° ìë™ ë‹µê¸€ ì„œë¹„ìŠ¤ - 24ì‹œê°„ ìë™í™”",
    version="2.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • ìˆ˜ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš© - ëª¨ë“  ì¶œì²˜ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"Unhandled exception: {type(exc).__name__}: {str(exc)}")
    logger.error(f"Traceback: {traceback.format_exc()}")
    
    return JSONResponse(
        status_code=500,
        content={
            "detail": str(exc),
            "type": type(exc).__name__,
            "path": str(request.url)
        }
    )

app.mount("/static", StaticFiles(directory=str(BASE_DIR / "web" / "static")), name="static")
templates = Jinja2Templates(directory=str(BASE_DIR / "web" / "templates"))

# ê¸°ì¡´ ë¼ìš°í„° ì„í¬íŠ¸
from api.routes import auth, pages, stores, reviews

# Step 4: ìƒˆë¡œìš´ ë‹µê¸€ ë“±ë¡ ê´€ë ¨ ë¼ìš°í„° ì„í¬íŠ¸
from api.routes import reply_posting_endpoints, reply_status

# í…ŒìŠ¤íŠ¸ìš© ë¼ìš°í„° ì„í¬íŠ¸
from api.routes import test_reply_posting

# ê¸°ì¡´ ë¼ìš°í„° ë“±ë¡
app.include_router(auth.router)
app.include_router(stores.router)
app.include_router(pages.router)
app.include_router(reviews.router)

# Step 4: ìƒˆë¡œìš´ ë¼ìš°í„° ë“±ë¡
app.include_router(reply_posting_endpoints.router)
app.include_router(reply_status.router)
app.include_router(reply_posting.router)

# í…ŒìŠ¤íŠ¸ìš© ë¼ìš°í„° ë“±ë¡
app.include_router(test_reply_posting.router)

async def startup_scheduler():
    """24ì‹œê°„ ìë™í™” ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •"""
    try:
        # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
        supabase_service = get_supabase_service()
        review_service = ReviewCollectorService(supabase_service)
        reply_service = ReplyPostingService(supabase_service)
        ai_service = AIService()
        
        # 1. ì¦‰ì‹œ í•œ ë²ˆ ì‹¤í–‰ (ì„œë²„ ì‹œì‘ ì‹œ)
        logger.info("=== ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸° ì‘ì—… ì‹¤í–‰ ===")
        
        # ë¨¼ì € ë¦¬ë·° ìˆ˜ì§‘ (ì§ì ‘ ì‹¤í–‰)
        logger.info("1. ë¦¬ë·° ìˆ˜ì§‘ ì‹œì‘...")
        try:
            result = await review_service.collect_all_stores_reviews()
            logger.info(f"ì´ˆê¸° ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ: {result}")
        except Exception as e:
            logger.error(f"ì´ˆê¸° ë¦¬ë·° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
        
        # 10ì´ˆ í›„ AI ë‹µê¸€ ìƒì„±
        await asyncio.sleep(10)
        logger.info("2. AI ë‹µê¸€ ìƒì„± ì‹œì‘...")
        try:
            await generate_ai_replies_job(ai_service, supabase_service)
        except Exception as e:
            logger.error(f"ì´ˆê¸° AI ë‹µê¸€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        # 20ì´ˆ í›„ ë‹µê¸€ ë“±ë¡
        await asyncio.sleep(10)
        logger.info("3. ë‹µê¸€ ë“±ë¡ ì‹œì‘...")
        try:
            await post_replies_batch_job(reply_service)
        except Exception as e:
            logger.error(f"ì´ˆê¸° ë‹µê¸€ ë“±ë¡ ì‹¤íŒ¨: {str(e)}")
        
        # 2. ì •ê¸° ìŠ¤ì¼€ì¤„ ì„¤ì • (AI ë‹µê¸€ ìƒì„±ì´ ë‹µê¸€ ë“±ë¡ë³´ë‹¤ ìš°ì„ )
        # 3ë¶„ë§ˆë‹¤ ë¦¬ë·° ìˆ˜ì§‘
        scheduler.add_job(
            collect_all_reviews_job,
            trigger=CronTrigger(minute="*/3"),
            id="review_collection",
            args=[review_service],
            name="ë¦¬ë·° ìˆ˜ì§‘ ì‘ì—…"
        )
        
        # 30ì´ˆë§ˆë‹¤ AI ë‹µê¸€ ìƒì„± (ìš°ì„ ìˆœìœ„ ë†’ì„)
        scheduler.add_job(
            generate_ai_replies_job,
            trigger=CronTrigger(second="*/30"),
            id="ai_reply_generation",
            args=[ai_service, supabase_service],
            name="AI ë‹µê¸€ ìƒì„± ì‘ì—…"
        )
        
        # 2ë¶„ë§ˆë‹¤ ë‹µê¸€ ë“±ë¡ (AI ìƒì„± í›„ ì‹¤í–‰)
        scheduler.add_job(
            post_replies_batch_job,
            trigger=CronTrigger(minute="*/2"),
            id="reply_posting",
            args=[reply_service],
            name="ë‹µê¸€ ë“±ë¡ ì‘ì—…"
        )
        
        scheduler.start()
        logger.info("=== ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤ ===")
        logger.info("ìë™í™” ëª¨ë“œ: ë¦¬ë·° ìˆ˜ì§‘(3ë¶„), AI ìƒì„±(30ì´ˆ), ë‹µê¸€ ë“±ë¡(2ë¶„) ê°„ê²©")
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
        logger.error(traceback.format_exc())

async def setup_scheduler_only():
    """ìŠ¤ì¼€ì¤„ëŸ¬ë§Œ ë“±ë¡, ì¦‰ì‹œ ì‹¤í–‰ ì•ˆí•¨ - ì›¹ì„œë²„ ëª¨ë“œìš©"""
    try:
        # ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„ (ê¸°ì¡´ê³¼ ë™ì¼)
        supabase_service = get_supabase_service()
        review_service = ReviewCollectorService(supabase_service)
        reply_service = ReplyPostingService(supabase_service)
        ai_service = AIService()
        
        logger.info("=== ìŠ¤ì¼€ì¤„ëŸ¬ë§Œ ë“±ë¡ ì‹œì‘ (ì¦‰ì‹œ ì‹¤í–‰ ì—†ìŒ) ===")
        
        # 1. ë¦¬ë·° ìˆ˜ì§‘ ì‘ì—… - 4ì‹œê°„ë§ˆë‹¤ (ìš´ì˜ í™˜ê²½)
        scheduler.add_job(
            collect_all_reviews_job,
            CronTrigger(hour="*/4"),  # 4ì‹œê°„ë§ˆë‹¤
            args=[review_service],
            id="review_collection",
            name="ë¦¬ë·° ìˆ˜ì§‘ ì‘ì—…",
            replace_existing=True
        )
        
        # 2. AI ë‹µê¸€ ìƒì„± ì‘ì—… - 30ë¶„ë§ˆë‹¤
        scheduler.add_job(
            generate_ai_replies_job,
            CronTrigger(minute="*/30"),  # 30ë¶„ë§ˆë‹¤
            args=[ai_service, supabase_service],
            id="ai_reply_generation",
            name="AI ë‹µê¸€ ìƒì„± ì‘ì—…",
            replace_existing=True
        )
        
        # 3. ë‹µê¸€ ë“±ë¡ ì‘ì—… - 4ì‹œê°„ë§ˆë‹¤ (1ì¼/2ì¼ ì§€ì—° ë¡œì§ í¬í•¨)
        scheduler.add_job(
            post_replies_batch_job,
            CronTrigger(hour="*/4"),  # 4ì‹œê°„ë§ˆë‹¤
            args=[reply_service],
            id="reply_posting",
            name="ë‹µê¸€ ë“±ë¡ ì‘ì—… (1ì¼/2ì¼ ì§€ì—°)",
            replace_existing=True
        )
        
        scheduler.start()
        logger.info("=== ìŠ¤ì¼€ì¤„ëŸ¬ ë“±ë¡ ì™„ë£Œ (ì›¹ì„œë²„ ëª¨ë“œ) ===")
        logger.info("ìš´ì˜ ëª¨ë“œ: ë¦¬ë·° ìˆ˜ì§‘(4ì‹œê°„), AI ìƒì„±(30ë¶„), ë‹µê¸€ ë“±ë¡(4ì‹œê°„) ê°„ê²©")
        logger.info("ë‹µê¸€ ì§€ì—°: ì¼ë°˜ 1ì¼, ì‚¬ì¥ë‹˜í™•ì¸ 2ì¼")
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ë“±ë¡ ì‹¤íŒ¨: {str(e)}")
        logger.error(traceback.format_exc())

# ë¦¬ë·° ìˆ˜ì§‘ ì‘ì—…
async def collect_all_reviews_job(review_service: ReviewCollectorService):
    """ëª¨ë“  í™œì„± ë§¤ì¥ì˜ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤ì¼€ì¤„ ì‘ì—…"""
    try:
        logger.info("=== ë¦¬ë·° ìë™ ìˆ˜ì§‘ ì‹œì‘ ===")
        start_time = time.time()
        
        result = await review_service.collect_all_stores_reviews()
        
        elapsed_time = time.time() - start_time
        logger.info(f"ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ: {result} (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        
    except Exception as e:
        logger.error(f"ë¦¬ë·° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        logger.error(traceback.format_exc())

# AI ë‹µê¸€ ìƒì„± ì‘ì—…
async def generate_ai_replies_job(ai_service: AIService, supabase_service: SupabaseService):
    """ìƒˆ ë¦¬ë·°ì— ëŒ€í•œ AI ë‹µê¸€ ìë™ ìƒì„±"""
    try:
        logger.info("=== AI ë‹µê¸€ ìë™ ìƒì„± ì‹œì‘ ===")
        
        # ë‹µê¸€ì´ ì—†ëŠ” ë¦¬ë·° ì¡°íšŒ
        new_reviews = await supabase_service.get_reviews_without_reply()
        
        if not new_reviews:
            logger.info("AI ë‹µê¸€ ìƒì„±í•  ìƒˆ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
            
        logger.info(f"{len(new_reviews)}ê°œ ë¦¬ë·°ì— ëŒ€í•œ AI ë‹µê¸€ ìƒì„± ì‹œì‘")
        
        # ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¸ë§ˆí¬ì–´ (ë™ì‹œ 5ê°œ)
        semaphore = asyncio.Semaphore(5)
        
        async def generate_with_limit(review):
            async with semaphore:
                try:
                    # ë§¤ì¥ ì •ì±… ì¡°íšŒ
                    policy = await supabase_service.get_store_reply_rules(review['store_code'])
                    
                    # AI ë‹µê¸€ ìƒì„±
                    reply_result = await ai_service.generate_reply(
                        review_data=review,
                        store_rules=policy
                    )
                    
                    # DBì— ì €ì¥
                    if reply_result['success']:
                        # ë‹µê¸€ ì €ì¥ ë° ìƒíƒœ ì—…ë°ì´íŠ¸ (ìˆ˜ë™ ì‹œìŠ¤í…œê³¼ ë™ì¼)
                        await supabase_service.save_ai_reply(
                            review['review_id'],
                            reply_result['reply'],
                            reply_result.get('quality_score', 0.8)
                        )
                        
                        # ìƒì„± ì´ë ¥ ì €ì¥ (ìˆ˜ë™ ì‹œìŠ¤í…œê³¼ ë™ì¼)
                        await supabase_service.save_reply_generation_history(
                            review_id=review['review_id'],
                            user_code='SYSTEM',  # ìë™í™” ì‹œìŠ¤í…œ
                            generation_type='ai_auto',  # ìë™ ìƒì„±
                            prompt_used=reply_result.get('prompt_used', ''),
                            model_version=reply_result.get('model_used', 'gpt-4o-mini'),
                            generated_content=reply_result['reply'],
                            quality_score=reply_result['quality_score'],
                            processing_time_ms=reply_result.get('processing_time_ms', 0),
                            token_usage=reply_result.get('token_usage', 0),
                            is_selected=True  # ìë™í™”ì—ì„œëŠ” ë°”ë¡œ ì„ íƒë¨
                        )
                        
                        # boss_review_needed, review_reason, urgency_score ì²˜ë¦¬
                        boss_review_needed = reply_result.get('boss_review_needed', False)
                        review_reason = reply_result.get('review_reason', '')
                        urgency_score = reply_result.get('urgency_score', 0.3)
                        quality_score = reply_result.get('quality_score', 0.8)
                        rating = review.get('rating', 5)
                        
                        # ìë™ ë“±ë¡ ì—¬ë¶€ ê²°ì • (ìŠ¤ë§ˆíŠ¸ ìë™í™”)
                        auto_post_status = 'generated'  # ê¸°ë³¸ê°’: ìˆ˜ë™ ê²€í†  í•„ìš”
                        
                        # ë†’ì€ ë³„ì  + ë†’ì€ í’ˆì§ˆ + ì‚¬ì¥ë‹˜ ê²€í†  ë¶ˆí•„ìš” â†’ ìë™ ë“±ë¡ ëŒ€ê¸°
                        if (rating >= 4 and 
                            quality_score >= 0.7 and 
                            not boss_review_needed and
                            urgency_score < 0.5):
                            auto_post_status = 'ready_to_post'  # ìë™ ë“±ë¡ ëŒ€ê¸°
                            logger.info(f"ë¦¬ë·° {review['review_id']} ìë™ ë“±ë¡ ëŒ€ê¸° ìƒíƒœë¡œ ì„¤ì • (ë³„ì : {rating}, í’ˆì§ˆ: {quality_score:.2f})")
                        else:
                            logger.info(f"ë¦¬ë·° {review['review_id']} ìˆ˜ë™ ê²€í†  í•„ìš” (ë³„ì : {rating}, í’ˆì§ˆ: {quality_score:.2f}, ì‚¬ì¥ë‹˜ê²€í† : {boss_review_needed})")
                        
                        # ìƒíƒœ ì—…ë°ì´íŠ¸ (ìˆ˜ë™ ì‹œìŠ¤í…œê³¼ ë™ì¼í•œ ë°©ì‹)
                        await supabase_service.update_review_status(
                            review_id=review['review_id'],
                            status=auto_post_status,
                            reply_content=reply_result['reply'],
                            reply_type='ai_auto',
                            reply_by='AI_AUTO',
                            boss_review_needed=boss_review_needed,  # íŒŒë¼ë¯¸í„°ëª…ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ë©”ì„œë“œì—ì„œ boss_reply_neededë¡œ ë³€í™˜)
                            review_reason=review_reason,
                            urgency_score=urgency_score
                        )
                    else:
                        # ë‹µê¸€ ìƒì„± ì‹¤íŒ¨ì‹œ ë¡œê·¸ ê¸°ë¡
                        logger.error(f"ë‹µê¸€ ìƒì„± ì‹¤íŒ¨: {reply_result.get('error', 'Unknown error')}")
                        return {"success": False, "review_id": review['review_id'], "error": reply_result.get('error')}
                    
                    return {"success": True, "review_id": review['review_id']}
                    
                except Exception as e:
                    logger.error(f"AI ë‹µê¸€ ìƒì„± ì‹¤íŒ¨ - review_id: {review['review_id']}, error: {str(e)}")
                    return {"success": False, "review_id": review['review_id'], "error": str(e)}
        
        # ëª¨ë“  ë¦¬ë·° ë³‘ë ¬ ì²˜ë¦¬
        tasks = [generate_with_limit(review) for review in new_reviews]
        results = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ ì§‘ê³„
        success_count = sum(1 for r in results if r and r.get('success', False))
        logger.info(f"AI ë‹µê¸€ ìƒì„± ì™„ë£Œ: {success_count}/{len(new_reviews)} ì„±ê³µ")
        
    except Exception as e:
        logger.error(f"AI ë‹µê¸€ ìƒì„± ì‘ì—… ì‹¤íŒ¨: {str(e)}")

# ë‹¨ì¼ ë¦¬ë·° AI ë‹µê¸€ ìƒì„± í—¬í¼ í•¨ìˆ˜
async def generate_single_reply(ai_service: AIService, supabase_service: SupabaseService, review: dict):
    """ë‹¨ì¼ ë¦¬ë·°ì— ëŒ€í•œ AI ë‹µê¸€ ìƒì„±"""
    try:
        # ë§¤ì¥ ì •ë³´ ì¡°íšŒ
        stores = await supabase_service.get_stores_by_user('all')
        store_info = None
        for store in stores:
            if store['store_code'] == review['store_code']:
                store_info = store
                break
                
        if not store_info:
            logger.error(f"ë§¤ì¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {review['store_code']}")
            return False

        # AI ë‹µê¸€ ìƒì„±
        reply = await ai_service.generate_reply(
            review_data={
                'review_content': review['review_content'],
                'rating': review.get('rating', 5),
                'review_name': review.get('review_name', 'ê³ ê°')
            },
            store_rules={
                'greeting_start': store_info.get('greeting_start', 'ì•ˆë…•í•˜ì„¸ìš”'),
                'greeting_end': store_info.get('greeting_end', 'ê°ì‚¬í•©ë‹ˆë‹¤'),
                'role': store_info.get('role', ''),
                'tone': store_info.get('tone', ''),
                'prohibited_words': store_info.get('prohibited_words', []),
                'max_length': store_info.get('max_length', 300)
            }
        )
        
        if not reply.get('success'):
            logger.error(f"AI ë‹µê¸€ ìƒì„± ì‹¤íŒ¨: {reply.get('error')}")
            return False
        
        # DBì— ì €ì¥
        saved = await supabase_service.save_ai_reply(
            review_id=review['review_id'],
            ai_response=reply.get('reply', ''),
            quality_score=reply.get('quality_score', 0.8)
        )
        
        if saved:
            logger.info(f"ë¦¬ë·° {review['review_id']} AI ë‹µê¸€ ìƒì„± ë° ì €ì¥ ì„±ê³µ")
            return True
        else:
            logger.error(f"ë¦¬ë·° {review['review_id']} AI ë‹µê¸€ ì €ì¥ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"ë¦¬ë·° {review['review_id']} ë‹µê¸€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise

async def post_replies_batch_job(reply_service: ReplyPostingService):
    """ìƒì„±ëœ AI ë‹µê¸€ì„ ì¼ê´„ ë“±ë¡ - 1ì¼/2ì¼ ì§€ì—° ë¡œì§ ì ìš©"""
    try:
        logger.info("=== ë‹µê¸€ ì¼ê´„ ë“±ë¡ ì‹œì‘ ===")
        
        supabase = reply_service.supabase
        now = datetime.now()
        one_day_ago = now - timedelta(days=1)
        two_days_ago = now - timedelta(days=2)
        
        # 1. ì¼ë°˜ ë‹µê¸€: 1ì¼ ì§€ë‚œ ê²ƒë§Œ (ì‚¬ì¥ë‹˜ í™•ì¸ ë¶ˆí•„ìš”)
        # 30ì¼ ì´ë‚´ ë¦¬ë·°ë§Œ ì„ íƒ (ë°°ë¯¼ ë“±ì˜ ë‹µê¸€ ë“±ë¡ ì œí•œ ê³ ë ¤)
        thirty_days_ago = now - timedelta(days=30)
        
        logger.info(f"ì§€ì—° ì¡°ê±´ í™•ì¸: í˜„ì¬ì‹œê°„={now.strftime('%Y-%m-%d %H:%M')}, 1ì¼ì „={one_day_ago.date()}, 2ì¼ì „={two_days_ago.date()}")
        
        normal_replies = await supabase._execute_query(
            supabase.client.table('reviews')
            .select('*')
            .in_('response_status', ['ready_to_post', 'generated'])
            .or_('boss_reply_needed.is.null,boss_reply_needed.eq.false')  # nullì´ê±°ë‚˜ false
            .lte('review_date', one_day_ago.date().isoformat())  # 1ì¼ ì´ì „ (lteë¡œ ë³€ê²½)
            .gte('review_date', thirty_days_ago.date().isoformat())  # 30ì¼ ì´ë‚´ë§Œ (gteë¡œ ë³€ê²½)
            .order('review_date', desc=False)
            .limit(15)
        )
        
        # 2. ì‚¬ì¥ë‹˜ í™•ì¸ í•„ìš”: 2ì¼ ì§€ë‚œ ê²ƒë§Œ (30ì¼ ì´ë‚´)
        boss_review_replies = await supabase._execute_query(
            supabase.client.table('reviews')
            .select('*')
            .in_('response_status', ['ready_to_post', 'generated'])
            .eq('boss_reply_needed', True)  # ì‚¬ì¥ë‹˜ í™•ì¸ í•„ìš”
            .lte('review_date', two_days_ago.date().isoformat())  # 2ì¼ ì´ì „ (lteë¡œ ë³€ê²½)
            .gte('review_date', thirty_days_ago.date().isoformat())  # 30ì¼ ì´ë‚´ë§Œ (gteë¡œ ë³€ê²½)
            .order('review_date', desc=False)
            .limit(5)
        )
        
        # ë‘ ê·¸ë£¹ í•©ì¹˜ê¸°
        all_reviews = []
        if normal_replies.data:
            all_reviews.extend(normal_replies.data)
        if boss_review_replies.data:
            all_reviews.extend(boss_review_replies.data)
        
        if not all_reviews:
            logger.info("ë“±ë¡í•  ë‹µê¸€ì´ ì—†ìŠµë‹ˆë‹¤ (1ì¼/2ì¼ ì§€ì—° ì¡°ê±´ ë¯¸ì¶©ì¡±)")
            return
        
        logger.info(f"ë‹µê¸€ ë“±ë¡ ëŒ€ìƒ: ì¼ë°˜ {len(normal_replies.data if normal_replies.data else [])}ê°œ, "
                   f"ì‚¬ì¥ë‹˜í™•ì¸ {len(boss_review_replies.data if boss_review_replies.data else [])}ê°œ")
        
        # í”Œë«í¼ë³„ ê·¸ë£¹í•‘ìœ¼ë¡œ íš¨ìœ¨ì  ì²˜ë¦¬
        success_count = 0
        fail_count = 0
        
        # ë§¤ì¥ ì •ë³´ í•œ ë²ˆë§Œ ì¡°íšŒ (platform_reply_rulesì—ì„œ)
        try:
            # platform_reply_rules í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ
            stores_query = supabase.client.table('platform_reply_rules').select('*').eq('is_active', True)
            stores_response = await supabase._execute_query(stores_query)
            
            if not stores_response.data:
                logger.warning("í™œì„±í™”ëœ ë§¤ì¥ì´ ì—†ìŠµë‹ˆë‹¤")
                return
            
            store_map = {store['store_code']: store for store in stores_response.data}
            logger.info(f"ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {len(store_map)}ê°œ ë§¤ì¥")
            
        except Exception as e:
            logger.error(f"ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return
        
        # í”Œë«í¼ë³„ë¡œ ê·¸ë£¹í•‘
        platform_groups = {}
        for review in all_reviews:
            platform = review.get('platform')
            platform_code = review.get('platform_code')
            store_code = review.get('store_code')
            
            if not all([platform, platform_code, store_code]):
                logger.error(f"í•„ìˆ˜ ì •ë³´ ëˆ„ë½: {review['review_id']}")
                fail_count += 1
                continue
                
            # ë§¤ì¥ ì •ë³´ í™•ì¸
            store_info = store_map.get(store_code)
            if not store_info:
                logger.error(f"ë§¤ì¥ ì •ë³´ ì—†ìŒ: {store_code}")
                fail_count += 1
                continue
            
            # í”Œë«í¼+ê³„ì •ë³„ë¡œ ê·¸ë£¹í•‘ (ë§¤ì¥ ì •ë³´ í¬í•¨)
            group_key = f"{platform}_{platform_code}"
            if group_key not in platform_groups:
                # ë¹„ë°€ë²ˆí˜¸ ë³µí˜¸í™”
                encrypted_pw = store_info.get('platform_pw', '')
                decrypted_pw = decrypt_password(encrypted_pw) if encrypted_pw else ''
                
                # ë³µí˜¸í™”ëœ ë§¤ì¥ ì •ë³´ ìƒì„±
                decrypted_store_info = store_info.copy()
                decrypted_store_info['platform_pw'] = decrypted_pw
                
                platform_groups[group_key] = {
                    'platform': platform,
                    'platform_code': platform_code,
                    'store_info': decrypted_store_info,  # ë³µí˜¸í™”ëœ ë§¤ì¥ ì •ë³´ í¬í•¨
                    'platform_id': store_info.get('platform_id'),
                    'platform_pw': decrypted_pw,  # ë³µí˜¸í™”ëœ ë¹„ë°€ë²ˆí˜¸
                    'store_name': store_info.get('store_name'),
                    'user_code': store_info.get('owner_user_code'),  # ì˜¬ë°”ë¥¸ í•„ë“œëª…
                    'reviews': []
                }
                
                logger.info(f"ë¹„ë°€ë²ˆí˜¸ ë³µí˜¸í™” ì™„ë£Œ: {platform_code} (ì•”í˜¸í™”: {len(encrypted_pw)}ì -> ë³µí˜¸í™”: {len(decrypted_pw)}ì)")
            platform_groups[group_key]['reviews'].append(review)
        
        logger.info(f"í”Œë«í¼ë³„ ê·¸ë£¹í•‘ ì™„ë£Œ: {len(platform_groups)}ê°œ ê·¸ë£¹")
        
        # ê° í”Œë«í¼ë³„ë¡œ ì¼ê´„ ì²˜ë¦¬
        for group_key, group_data in platform_groups.items():
            try:
                platform = group_data['platform']
                platform_code = group_data['platform_code']
                user_code = group_data['user_code']
                reviews = group_data['reviews']
                
                logger.info(f"=== {platform} ({platform_code}) ì¼ê´„ ì²˜ë¦¬ ì‹œì‘: {len(reviews)}ê°œ ë¦¬ë·° ===")
                
                # í”Œë«í¼ë³„ ì¼ê´„ ì²˜ë¦¬ (ë§¤ì¥ ì •ë³´ í¬í•¨)
                result = await reply_service.post_batch_replies_by_platform(
                    platform=platform,
                    platform_code=platform_code,
                    user_code=user_code,
                    reviews=reviews,
                    store_info=group_data['store_info']  # ë§¤ì¥ ì •ë³´ ì§ì ‘ ì „ë‹¬
                )
                
                batch_success = result.get('success_count', 0)
                batch_fail = result.get('fail_count', 0)
                
                success_count += batch_success
                fail_count += batch_fail
                
                logger.info(f"{platform} ({platform_code}) ì™„ë£Œ: {batch_success}ê°œ ì„±ê³µ, {batch_fail}ê°œ ì‹¤íŒ¨")
                
            except Exception as e:
                logger.error(f"í”Œë«í¼ ì¼ê´„ ì²˜ë¦¬ ì‹¤íŒ¨ - {group_key}: {str(e)}")
                fail_count += len(group_data['reviews'])
        
        logger.info(f"ì „ì²´ ë‹µê¸€ ì¼ê´„ ë“±ë¡ ì™„ë£Œ: {success_count}ê°œ ì„±ê³µ, {fail_count}ê°œ ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"ë‹µê¸€ ì¼ê´„ ë“±ë¡ ì‘ì—… ì‹¤íŒ¨: {str(e)}")
        
# ì¼ì¼ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„± (ì„ íƒì‚¬í•­)
async def generate_daily_report(supabase_service: SupabaseService):
    """ë§¤ì¼ ìì • í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        logger.info("=== ì¼ì¼ í†µê³„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘ ===")
        
        # ì˜¤ëŠ˜ ë‚ ì§œ
        today = datetime.now().date()
        
        # í†µê³„ ë°ì´í„° ìˆ˜ì§‘ (ì˜ˆì‹œ)
        stats = {
            "date": today.isoformat(),
            "total_reviews_collected": 0,
            "total_replies_generated": 0,
            "total_replies_posted": 0,
            "success_rate": 0.0
        }
        
        # TODO: ì‹¤ì œ í†µê³„ ë¡œì§ êµ¬í˜„
        logger.info(f"ì¼ì¼ í†µê³„: {stats}")
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

# ë””ë²„ê¹…ìš© - ë“±ë¡ëœ ë¼ìš°íŠ¸ ì¶œë ¥
@app.on_event("startup")
async def startup_event():
    routes = []
    for route in app.routes:
        if hasattr(route, "path"):
            routes.append(f"{route.methods} {route.path}")
    logger.info(f"Registered routes: {routes}")

# ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ API
@app.get("/api/scheduler/status")
async def scheduler_status():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸"""
    jobs = []
    for job in scheduler.get_jobs():
        jobs.append({
            "id": job.id,
            "name": job.name,
            "next_run_time": job.next_run_time.isoformat() if job.next_run_time else None,
            "trigger": str(job.trigger)
        })
    
    return {
        "scheduler_running": scheduler.running,
        "jobs": jobs,
        "current_time": datetime.now().isoformat()
    }

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ì—… ìˆ˜ë™ ì‹¤í–‰ API
@app.post("/api/scheduler/run/{job_id}")
async def run_scheduler_job(job_id: str):
    """íŠ¹ì • ìŠ¤ì¼€ì¤„ ì‘ì—…ì„ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰"""
    try:
        job = scheduler.get_job(job_id)
        if not job:
            return {"success": False, "error": f"Job {job_id} not found"}
        
        # ì‘ì—… ì¦‰ì‹œ ì‹¤í–‰
        job.modify(next_run_time=datetime.now())
        
        return {
            "success": True,
            "message": f"Job {job_id} scheduled for immediate execution"
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

@app.get("/api")
async def api_info():
    return {
        "message": "ë¦¬ë·° ìë™í™” API - 24ì‹œê°„ ìë™í™” êµ¬í˜„ ì™„ë£Œ",
        "version": "2.0.0",
        "features": [
            "ë¦¬ë·° ìˆ˜ì§‘ (30ë¶„ë§ˆë‹¤ ìë™)",
            "AI ë‹µê¸€ ìƒì„± (5ë¶„ë§ˆë‹¤ ìë™)",
            "ë‹µê¸€ ë“±ë¡ (10ë¶„ë§ˆë‹¤ ìë™, 08-22ì‹œ)",
            "ì¼ê´„ ì²˜ë¦¬",
            "ìƒíƒœ ì¡°íšŒ",
            "24ì‹œê°„ ìë™í™”"
        ],
        "scheduler": {
            "status": "running" if scheduler.running else "stopped",
            "jobs_count": len(scheduler.get_jobs())
        },
        "docs": "/docs",
        "redoc": "/redoc"
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "review-automation-api",
        "version": "2.0.0",
        "scheduler_running": scheduler.running,
        "timestamp": datetime.now().isoformat()
    }

@app.get("/api/test")
async def test_endpoint():
    return {
        "message": "API is working",
        "timestamp": datetime.now().isoformat()
    }

# Step 4: ìƒˆë¡œìš´ API ì—”ë“œí¬ì¸íŠ¸ ìš”ì•½
@app.get("/api/endpoints")
async def list_endpoints():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡
    """
    return {
        "ê¸°ì¡´_ì—”ë“œí¬ì¸íŠ¸": {
            "ì¸ì¦": "/api/auth/*",
            "ë§¤ì¥_ê´€ë¦¬": "/api/stores/*",
            "ë¦¬ë·°_ê´€ë¦¬": "/api/reviews/*",
            "í˜ì´ì§€": "/api/pages/*"
        },
        "Step4_ìƒˆë¡œìš´_ì—”ë“œí¬ì¸íŠ¸": {
            "ë‹µê¸€_ë“±ë¡": {
                "ë‹¨ì¼_ë‹µê¸€_ë“±ë¡": "POST /api/reply-posting/{review_id}/submit",
                "ë§¤ì¥ë³„_ì¼ê´„_ë“±ë¡": "POST /api/reply-posting/batch/{store_code}/submit",
                "ì „ì²´_ë§¤ì¥_ì¼ê´„_ë“±ë¡": "POST /api/reply-posting/batch/all-stores/submit"
            },
            "ìƒíƒœ_ì¡°íšŒ": {
                "ëŒ€ê¸°_ë‹µê¸€_ì¡°íšŒ": "GET /api/reply-status/{store_code}/pending",
                "ë‹µê¸€_ìƒíƒœ_ì¡°íšŒ": "GET /api/reply-status/{review_id}/status",
                "ë§¤ì¥_ìš”ì•½_ì¡°íšŒ": "GET /api/reply-status/stores/{user_code}/summary",
                "ë‹µê¸€_ì¬ì‹œë„": "POST /api/reply-status/{review_id}/retry"
            }
        },
        "24ì‹œê°„_ìë™í™”_ì—”ë“œí¬ì¸íŠ¸": {
            "ìŠ¤ì¼€ì¤„ëŸ¬_ìƒíƒœ": "GET /api/scheduler/status",
            "ì‘ì—…_ìˆ˜ë™_ì‹¤í–‰": "POST /api/scheduler/run/{job_id}"
        },
        "í…ŒìŠ¤íŠ¸ìš©_ì—”ë“œí¬ì¸íŠ¸": {
            "í…ŒìŠ¤íŠ¸_ë‹µê¸€_ë“±ë¡": "POST /api/test-reply-posting/{review_id}/submit",
            "ë¦¬ë·°_ì •ë³´_ì¡°íšŒ": "GET /api/test-reply-posting/{review_id}/info",
            "ë§¤ì¥_ì •ë³´_ì¡°íšŒ": "GET /api/test-reply-posting/stores/{store_code}/info"
        },
        "ë¬¸ì„œ": {
            "Swagger_UI": "/docs",
            "ReDoc": "/redoc"
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )